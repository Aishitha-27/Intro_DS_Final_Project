<<<<<<< Updated upstream
fancyRpartPlot(regression_tree)
residuals_tree <- test_data1$total_sales_revenue - predict(regression_tree, test_data1)
MAE_tree <- mean(abs(residuals_tree))
RMSE_tree <- sqrt(mean(residuals_tree^2))
SS_total_tree <- sum((test_data1$total_sales_revenue - mean(test_data1$total_sales_revenue))^2)
SS_residual_tree <- sum(residuals_tree^2)
R_squared_tree <- 1 - (SS_residual_tree / SS_total_tree)
n <- nrow(test_data1)  # number of d
p <- length(coef(regression_tree))  # number of predictors
Adjusted_R_squared_tree <- 1 - ((1 - R_squared_tree) * (n - 1)) / (n - p - 1)
cat("MAE (Tree):", MAE_tree, "\n")
cat("RMSE (Tree):", RMSE_tree, "\n")
cat("R-squared (Tree):", R_squared_tree, "\n")
cat("Adjusted R-squared (Tree):", Adjusted_R_squared_tree, "\n")
# Load caret library
library(caret)
# Predictions already made using your model
predictions <- predict(classification_tree, test_data, type = "class")
# Load caret library
library(caret)
# Predictions already made using your model
predictions <- predict(classification_tree, test_data, type = "class")
set.seed(1)
kyphosisfit <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis, method="class", control = list(maxdepth = 4) )
# kyphosisfit <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis, method="class", control = {rpart.control list} )
# rpart.control(maxdepth = 30, minsplit = 20, minbucket = round(minsplit/3), cp = 0.01, maxcompete = 4, maxsurrogate = 5, usesurrogate = 2, xval = 10, surrogatestyle = 0, ...)
summary(kyphosisfit) # detailed summary of splits
# plot tree
plot(kyphosisfit, uniform=TRUE, main="Classification Tree for Kyphosis")
text(kyphosisfit, use.n=TRUE, all=TRUE, cex=.8)
library(caret)
cm = confusionMatrix( predict(classification_tree, type = "class"), reference = customer_segment[, "customer_segment"] )
library(caret)
cm = confusionMatrix( predict(classification_tree, type = "class"), reference = train_data[, "customer_segment"] )
predictions <- predict(classification_tree, test_data, type = "class")
predictions <- predict(classification_tree, test_data, type = "class")
predictions <- predict(classification_tree, test_data, type = "class")
confusion_matrix <- table(Actual = test_data$customer_segment, Predicted = test_data$predicted_segment)
print(confusion_matrix)
=======
RMSE <- sqrt(mean(residuals^2))
SS_total <- sum((test_data$total_sales_revenue - mean(test_data$total_sales_revenue))^2)
SS_residual <- sum(residuals^2)
R_squared <- 1 - (SS_residual / SS_total)
cat("MAE:", MAE, "\n")
cat("RMSE:", RMSE, "\n")
cat("R-squared:", R_squared, "\n")
regression_tree <- rpart(
total_sales_revenue ~ avg_discount + OrderPriority + Country + PaymentMethod + total_quantity_sold,data = train_data,method="anova")
summary(regression_tree)
importance_values <- as.data.frame(regression_tree$variable.importance)
var_importance <- data.frame(
Variable = rownames(importance_values),
Overall = as.numeric(importance_values$`regression_tree$variable.importance`)
)
rownames(var_importance) <- NULL
ggplot(var_importance, aes(x = reorder(Variable, Overall), y = Overall)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
labs(title = "Feature Importance",x = "Features",
y = "Importance")
fancyRpartPlot(regression_tree)
tree_predictions <- predict(regression_tree, test_data)
test_data$predicted_sales_tree <- tree_predictions
comparison_tree <- data.frame(Actual = test_data$total_sales_revenue,
Predicted = test_data$predicted_sales_tree)
head(comparison_tree, 10)
mae_value <- mae(comparison_tree$Actual, comparison_tree$Predicted)
rmse_value <- rmse(comparison_tree$Actual, comparison_tree$Predicted)
mape_value <- mape(comparison_tree$Actual, comparison_tree$Predicted)
cat("MAE:", mae_value, "\nRMSE:", rmse_value, "\nMAPE:", mape_value)
customer_data <- cleaned_data %>%
group_by(CustomerID) %>%
summarize(
purchase_frequency = n_distinct(InvoiceNo),
total_quantity = sum(Quantity, na.rm = TRUE),
total_spend = sum(UnitPrice * Quantity, na.rm = TRUE),
avg_discount = mean(Discount, na.rm = TRUE),
preferred_payment = as.character(names(sort(table(PaymentMethod), decreasing = TRUE)[1])),
preferred_category = as.character(names(sort(table(Category), decreasing = TRUE)[1]))
)
spend_summary <- summary(customer_data$total_spend)
low_threshold <- spend_summary["1st Qu."]
high_threshold <- spend_summary["3rd Qu."]
customer_data <- customer_data %>%
mutate(
customer_segment = case_when(
total_spend < low_threshold ~ "Low",
total_spend >= low_threshold & total_spend < high_threshold ~ "Medium",
total_spend >= high_threshold ~ "High"
)
)
customer_data$preferred_payment <-  as.factor(customer_data$preferred_payment)
customer_data$preferred_category <- as.factor(customer_data$preferred_category)
customer_data$preferred_payment <- as.numeric(customer_data$preferred_payment)
customer_data$preferred_category <- as.numeric(customer_data$preferred_category)
cor_matrix <- cor(customer_data %>%
select(purchase_frequency, total_quantity, avg_discount, preferred_payment, preferred_category),
use = "complete.obs")
corrplot(
cor_matrix,
method = "color",
type = "upper",
addCoef.col = "black",
tl.col = "black",
col = colorRampPalette(c("red", "white", "purple"))(200),
mar = c(0, 0, 1, 0))
set.seed(123)
train_indices <- sample(1:nrow(customer_data), 0.7 * nrow(customer_data))
train_data <- customer_data[train_indices, ]
test_data <- customer_data[-train_indices, ]
classification_tree <- rpart(
customer_segment ~ purchase_frequency + total_quantity + avg_discount + preferred_payment + preferred_category,
data = train_data,
method = "class"
)
summary(classification_tree)
fancyRpartPlot(classification_tree)
predictions <- predict(classification_tree, test_data, type = "class")
test_data$predicted_segment <- predictions
confusion_matrix <- table(Actual = test_data$customer_segment, Predicted = test_data$predicted_segment)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
# Convert customer_segment to binary indicators (one-vs-rest approach)
test_data_binary <- model.matrix(~ customer_segment - 1, data = test_data)
colnames(test_data_binary) <- levels(test_data$customer_segment)
# Predict probabilities for each class
predicted_probs <- predict(classification_tree, test_data, type = "prob")
# Plot ROC curves for each class
par(mfrow = c(1, 3))  # Set layout for 3 ROC curves
auc_values <- c()
for (class in colnames(test_data_binary)) {
roc_curve <- roc(test_data_binary[, class], predicted_probs[, class])
plot(roc_curve, main = paste("ROC for", class), col = "blue")
auc <- auc(roc_curve)
auc_values <- c(auc_values, auc)
}
# Combine AUC values into a data frame
auc_df <- data.frame(
Class = colnames(test_data_binary),
AUC = auc_values
)
print(auc_df)
logistic_data <- cleaned_data %>%
mutate(
SalesChannel = ifelse(SalesChannel == "Online", 1, 0)
) %>%
select(
SalesChannel, CustomerID, Quantity, UnitPrice, Discount, OrderPriority, Country, PaymentMethod
)
set.seed(123)
train_indices <- sample(1:nrow(logistic_data), 0.7 * nrow(logistic_data))
train_data <- logistic_data[train_indices, ]
test_data <- logistic_data[-train_indices, ]
logistic_model <- glm(
SalesChannel ~ Quantity + UnitPrice + Discount + OrderPriority + Country + PaymentMethod,
data = train_data,
family = "binomial"
)
summary(logistic_model)
predicted_probabilities <- predict(logistic_model, test_data, type = "response")
test_data$predicted_channel <- ifelse(predicted_probabilities > 0.5, 1, 0)
confusion_matrix <- table(Actual = test_data$SalesChannel, Predicted = test_data$predicted_channel)
print(confusion_matrix)
performance <- confusionMatrix(factor(test_data$predicted_channel), factor(test_data$SalesChannel))
accuracy <- performance$overall["Accuracy"]
print(accuracy)
predicted_probabilities <- predict(logistic_model, test_data, type = "response")
# Create the ROC curve
roc_curve <- roc(response = test_data$SalesChannel,
predictor = predicted_probabilities)
plot(roc_curve, col = "blue", main = "ROC Curve for Logistic Regression")
abline(a = 0, b = 1, col = "red", lty = 2)  # Diagonal line for random guessing
# Calculate and display the AUC
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
# Convert customer_segment to binary indicators (one-vs-rest approach)
test_data_binary <- model.matrix(~ customer_segment - 1, data = test_data)
knitr::opts_chunk$set(echo = TRUE)
>>>>>>> Stashed changes
library(ezids)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(outliers)
library(reshape2)
library(lubridate)
library(scales)
library(rpart)
library(rpart.plot)
library(caret)
library(magrittr)
library(Metrics)
library(rattle)
library(corrplot)
library(pROC)
<<<<<<< Updated upstream
data=read.csv("C:\\Users\\Cashapona\\Downloads\\online_sales_dataset.csv")
head(data, 5)
colSums(is.na(data_clean))
=======
data=read.csv("online_sales_dataset.csv")
head(data, 5)
str(data)
xkablesummary(data, title = "Summary of Dataset")
colSums(is.na(data))
data_clean<- na.omit(data)
colSums(is.na(data_clean))
dim(data_clean)
set.seed(123)
data_reduced <- data_clean %>% sample_n(10000)
dim(data_reduced)
ggplot(data_reduced, aes(x = "", y = Quantity)) +
geom_boxplot(fill = "lightblue", color = "darkblue") +
labs(title = "Boxplot of Quantity", y = "Quantity") +
theme_minimal()
ggplot(data_reduced, aes(x = "", y = UnitPrice)) +
geom_boxplot(fill = "lightblue", color = "darkblue") +
labs(title = "Boxplot of UnitPrice", y = "Unit Price") +
theme_minimal()
ggplot(data_reduced, aes(x = "", y = Discount)) +
geom_boxplot(fill = "lightblue", color = "darkblue") +
labs(title = "Boxplot of Discount", y = "Discount") +
theme_minimal()
>>>>>>> Stashed changes
kd2_outliers <- function(column) {
density <- density(column, na.rm = TRUE)
threshold <- 0.01  # Define a threshold for low-density regions
outlier_indices <- which(density(column)$y < threshold)
return(length(outlier_indices))  # Return the count of outliers
}
outliers_quantity <- kd2_outliers(data_reduced$Quantity)
outliers_unit_price <- kd2_outliers(data_reduced$UnitPrice)
outliers_discount <- kd2_outliers(data_reduced$Discount)
cat("Outliers in Quantity:", outliers_quantity, "\n")
cat("Outliers in Unit Price:", outliers_unit_price, "\n")
cat("Outliers in Discount:", outliers_discount, "\n")
remove_kd2_outliers <- function(df, column) {
density <- density(df[[column]], na.rm = TRUE)
threshold <- 0.01  # Define a threshold for low-density regions
outlier_indices <- which(density$y < threshold)
if (length(outlier_indices) > 0) {
df <- df[-outlier_indices, ]
}
return(df)
}
cleaned_data <- data_reduced %>%
remove_kd2_outliers("Quantity") %>%
remove_kd2_outliers("UnitPrice") %>%
remove_kd2_outliers("Discount")
<<<<<<< Updated upstream
=======
xkablesummary(cleaned_data)
cleaned_data$InvoiceDate <- as.Date(cleaned_data$InvoiceDate, format = "%d-%m-%Y")
cleaned_data$Description = as.factor(cleaned_data$Description)
cleaned_data$StockCode = as.factor(cleaned_data$StockCode)
cleaned_data$Country = as.factor(cleaned_data$Country)
cleaned_data$PaymentMethod = as.factor(cleaned_data$PaymentMethod)
cleaned_data$Category = as.factor(cleaned_data$Category)
cleaned_data$ReturnStatus = as.factor(cleaned_data$ReturnStatus)
cleaned_data$SalesChannel = as.factor(cleaned_data$SalesChannel)
cleaned_data$ShipmentProvider = as.factor(cleaned_data$ShipmentProvider)
cleaned_data$OrderPriority = as.factor(cleaned_data$OrderPriority)
cleaned_data$WarehouseLocation = as.factor(cleaned_data$WarehouseLocation)
str(cleaned_data)
cleaned_data$TotalSales <- cleaned_data$UnitPrice * cleaned_data$Quantity
sales_by_country <- cleaned_data %>%
group_by(Country) %>%
summarise(TotalSales = sum(TotalSales, na.rm = TRUE))
# Create the bar plot
ggplot(sales_by_country, aes(x = reorder(Country, TotalSales), y = TotalSales)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
labs(
title = "Total Sales by Country",
x = "Country",
y = "Total Sales"
) +
theme_light()
return_status_counts <- cleaned_data %>%
group_by(ReturnStatus) %>%
summarise(Count = n()) %>%
mutate(Percentage = (Count / sum(Count)) * 100)
ggplot(return_status_counts, aes(x = "", y = Count, fill = ReturnStatus)) +
geom_bar(stat = "identity", width = 1) +
coord_polar("y", start = 0) +
geom_text(aes(label = paste0(round(Percentage, 1), "%")), position = position_stack(vjust = 0.5)) +
labs(
title = "Proportion of Return Statuses",
x = NULL,
y = NULL
) +
theme_void() +
theme(legend.title = element_blank())
top_products <- cleaned_data %>%
group_by(Description) %>%
summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE)) %>%
arrange(desc(TotalSales)) %>%
slice(1:10)
ggplot(top_products, aes(x = reorder(Description, TotalSales), y = TotalSales)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(
title = "Top 10 Products by Total Sales",
x = "Product Description",
y = "Total Sales"
) +
theme_minimal()
cleaned_data <- cleaned_data %>%
mutate(Year = format(InvoiceDate, "%Y"))
category_sales_yearly <- cleaned_data %>%
group_by(Year, Category) %>%
summarise(
TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE),
.groups = "drop"
)
category_sales_yearly$Year <- factor(category_sales_yearly$Year, levels = unique(category_sales_yearly$Year))
ggplot(category_sales_yearly, aes(x = Year, y = TotalSales, fill = Category)) +
geom_bar(stat = "identity", position = "stack") +
labs(
title = "Stacked Sales by Category Over Time (Yearly)",
x = "Year",
y = "Total Sales",
fill = "Category"
) +
theme_minimal() +
scale_y_continuous(labels = comma) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Summarize total quantities for returned and not-returned items
sales_return_summary <- cleaned_data %>%
group_by(Description, ReturnStatus) %>%
summarise(
TotalQuantity = sum(Quantity, na.rm = TRUE),
.groups = "drop"
)
ggplot(sales_return_summary, aes(x = reorder(Description, TotalQuantity), y = TotalQuantity, fill = ReturnStatus)) +
geom_bar(stat = "identity", position = "stack") +
labs(
title = "Most Returned and Not Returned Items",
x = "Item Description",
y = "Total Quantity",
fill = "Return Status"
) +
scale_y_continuous(labels = scales::comma) +
coord_flip() +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5, face = "bold")
)
product_preferences <- cleaned_data %>%
group_by(Description, Country) %>%
summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE), .groups = "drop")
ggplot(product_preferences, aes(x = Description, y = TotalSales, fill = Country)) +
geom_bar(stat = "identity", position = "stack") +
labs(
title = "Product Preferences by Customer Type",
x = "Product",
y = "Total Sales",
fill = "Customer Type") +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5, face = "bold"))
unique(cleaned_data$PaymentMethod)
payment_segregation <- table(cleaned_data$PaymentMethod, cleaned_data$Category)
chisq_test <- chisq.test(payment_segregation)
print(chisq_test)
t_test <- t.test(Quantity ~ Discount > 0.1, data = cleaned_data)
print(t_test)
anova <- aov(ShippingCost ~ ShipmentProvider, data = cleaned_data)
summary(anova)
t_test2 <- t.test(Quantity ~ SalesChannel, data = cleaned_data)
print(t_test2)
return_category <- table(cleaned_data$ReturnStatus, cleaned_data$Category)
chisq_test2 <- chisq.test(return_category)
print(chisq_test2)
>>>>>>> Stashed changes
sales_data <- cleaned_data %>%
group_by(StockCode, OrderPriority, CustomerID) %>%
summarise(
avg_discount = mean(Discount, na.rm = TRUE),
total_sales_revenue = sum(UnitPrice * Quantity, na.rm = TRUE),
total_quantity_sold = sum(Quantity, na.rm = TRUE),
.groups = "drop"
)
customer_data <- cleaned_data %>%
select(CustomerID, Country, PaymentMethod) %>%
distinct(CustomerID, .keep_all = TRUE)
sales_data <- sales_data %>%
left_join(customer_data, by = "CustomerID")
<<<<<<< Updated upstream
lm_sales_model <- lm(
total_sales_revenue ~ avg_discount + OrderPriority + PaymentMethod + total_quantity_sold, data = train_data1)
summary(lm_sales_model)
lm_sales_model$coefficients
fitted_values <- lm_sales_model$fitted.values
residuals <- train_data1$total_sales_revenue - fitted_values
MAE <- mean(abs(residuals))
RMSE <- sqrt(mean(residuals^2))
SS_total <- sum((train_data1$total_sales_revenue - mean(train_data1$total_sales_revenue))^2)
SS_residual <- sum(residuals^2)
R_squared <- 1 - (SS_residual / SS_total)
n <- nrow(train_data1)
p <- length(coef(lm_sales_model)) - 1
Adjusted_R_squared <- 1 - ((1 - R_squared) * (n - 1)) / (n - p - 1)
cat("MAE:", MAE, "\n")
cat("RMSE:", RMSE, "\n")
cat("R-squared:", R_squared, "\n")
cat("Adjusted R-squared:", Adjusted_R_squared, "\n")
regression_tree <- rpart(
total_sales_revenue ~ avg_discount + OrderPriority + Country + PaymentMethod + total_quantity_sold,data = train_data,method="anova")
customer_data <- cleaned_data %>%
group_by(CustomerID) %>%
summarize(
purchase_frequency = n_distinct(InvoiceNo),
total_quantity = sum(Quantity, na.rm = TRUE),
total_spend = sum(UnitPrice * Quantity, na.rm = TRUE),
avg_discount = mean(Discount, na.rm = TRUE),
preferred_payment = as.character(names(sort(table(PaymentMethod), decreasing = TRUE)[1])),
preferred_category = as.character(names(sort(table(Category), decreasing = TRUE)[1]))
)
spend_summary <- summary(customer_data$total_spend)
low_threshold <- spend_summary["1st Qu."]
high_threshold <- spend_summary["3rd Qu."]
customer_data <- customer_data %>%
mutate(
customer_segment = case_when(
total_spend < low_threshold ~ "Low",
total_spend >= low_threshold & total_spend < high_threshold ~ "Medium",
total_spend >= high_threshold ~ "High"
)
)
customer_data$preferred_payment <-  as.factor(customer_data$preferred_payment)
customer_data$preferred_category <- as.factor(customer_data$preferred_category)
customer_data$preferred_payment <- as.numeric(customer_data$preferred_payment)
customer_data$preferred_category <- as.numeric(customer_data$preferred_category)
set.seed(123)
train_indices <- sample(1:nrow(customer_data), 0.7 * nrow(customer_data))
train_data <- customer_data[train_indices, ]
test_data <- customer_data[-train_indices, ]
classification_tree <- rpart(
customer_segment ~ purchase_frequency + total_quantity + avg_discount + preferred_payment + preferred_category,
data = train_data,
method = "class"
)
summary(classification_tree)
predictions <- predict(classification_tree, test_data, type = "class")
test_data$predicted_segment <- predictions
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_segment),    # Predicted values
reference = as.factor(test_data$customer_segment) # Actual values
)
# Print the confusion matrix
print(confusion_matrix)
predictions <- predict(classification_tree, test_data, type = "class")
# Add predictions to the test data
test_data$predicted_segment <- predictions
# Create a confusion matrix using the caret package
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_segment),    # Predicted values
reference = as.factor(test_data$customer_segment) # Actual values
)
# Print the confusion matrix
print(confusion_matrix
predictions <- predict(classification_tree, test_data, type = "class")
test_data$predicted_segment <- predictions
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_segment),
reference = as.factor(test_data$customer_segment))
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", confusion_matrix$accuracy, "\n")
cat("Accuracy:", confusion_matrix$overall["Accuracy"], "\n")
logistic_model$coefficients
predicted_probabilities <- predict(logistic_model, test_data, type = "response")
predicted_probabilities <- predict(logistic_model, test_data, type = "response")
=======
set.seed(123)
train_indices <- sample(1:nrow(sales_data), 0.7 * nrow(sales_data))
train_data <- sales_data[train_indices, ]
test_data <- sales_data[-train_indices, ]
cor_matrix <- cor(train_data %>% select(avg_discount, total_sales_revenue, total_quantity_sold))
corrplot(
cor_matrix,
method = "color",
type = "upper",
addCoef.col = "black",
tl.col = "black",
col = colorRampPalette(c("red", "white", "purple"))(200))
lm_sales_model <- lm(
total_sales_revenue ~ avg_discount + OrderPriority + Country + PaymentMethod + total_quantity_sold,
data = train_data)
summary(lm_sales_model)
predictions <- predict(lm_sales_model, test_data)
test_data$predicted_sales <- predictions
comparison <- data.frame(Actual = test_data$total_sales_revenue,
Predicted = test_data$predicted_sales)
head(comparison, 10)
residuals <- test_data$total_sales_revenue - predictions
MAE <- mean(abs(residuals))
RMSE <- sqrt(mean(residuals^2))
SS_total <- sum((test_data$total_sales_revenue - mean(test_data$total_sales_revenue))^2)
SS_residual <- sum(residuals^2)
R_squared <- 1 - (SS_residual / SS_total)
cat("MAE:", MAE, "\n")
cat("RMSE:", RMSE, "\n")
cat("R-squared:", R_squared, "\n")
regression_tree <- rpart(
total_sales_revenue ~ avg_discount + OrderPriority + Country + PaymentMethod + total_quantity_sold,data = train_data,method="anova")
summary(regression_tree)
importance_values <- as.data.frame(regression_tree$variable.importance)
var_importance <- data.frame(
Variable = rownames(importance_values),
Overall = as.numeric(importance_values$`regression_tree$variable.importance`)
)
rownames(var_importance) <- NULL
ggplot(var_importance, aes(x = reorder(Variable, Overall), y = Overall)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
labs(title = "Feature Importance",x = "Features",
y = "Importance")
fancyRpartPlot(regression_tree)
tree_predictions <- predict(regression_tree, test_data)
test_data$predicted_sales_tree <- tree_predictions
comparison_tree <- data.frame(Actual = test_data$total_sales_revenue,
Predicted = test_data$predicted_sales_tree)
head(comparison_tree, 10)
mae_value <- mae(comparison_tree$Actual, comparison_tree$Predicted)
rmse_value <- rmse(comparison_tree$Actual, comparison_tree$Predicted)
mape_value <- mape(comparison_tree$Actual, comparison_tree$Predicted)
cat("MAE:", mae_value, "\nRMSE:", rmse_value, "\nMAPE:", mape_value)
>>>>>>> Stashed changes
customer_data <- cleaned_data %>%
group_by(CustomerID) %>%
summarize(
purchase_frequency = n_distinct(InvoiceNo),
total_quantity = sum(Quantity, na.rm = TRUE),
total_spend = sum(UnitPrice * Quantity, na.rm = TRUE),
avg_discount = mean(Discount, na.rm = TRUE),
preferred_payment = as.character(names(sort(table(PaymentMethod), decreasing = TRUE)[1])),
preferred_category = as.character(names(sort(table(Category), decreasing = TRUE)[1]))
)
spend_summary <- summary(customer_data$total_spend)
low_threshold <- spend_summary["1st Qu."]
high_threshold <- spend_summary["3rd Qu."]
customer_data <- customer_data %>%
mutate(
customer_segment = case_when(
total_spend < low_threshold ~ "Low",
total_spend >= low_threshold & total_spend < high_threshold ~ "Medium",
total_spend >= high_threshold ~ "High"
)
)
customer_data$preferred_payment <-  as.factor(customer_data$preferred_payment)
customer_data$preferred_category <- as.factor(customer_data$preferred_category)
customer_data$preferred_payment <- as.numeric(customer_data$preferred_payment)
customer_data$preferred_category <- as.numeric(customer_data$preferred_category)
cor_matrix <- cor(customer_data %>%
select(purchase_frequency, total_quantity, avg_discount, preferred_payment, preferred_category),
use = "complete.obs")
corrplot(
cor_matrix,
method = "color",
type = "upper",
addCoef.col = "black",
tl.col = "black",
col = colorRampPalette(c("red", "white", "purple"))(200),
mar = c(0, 0, 1, 0))
set.seed(123)
train_indices <- sample(1:nrow(customer_data), 0.7 * nrow(customer_data))
train_data <- customer_data[train_indices, ]
test_data <- customer_data[-train_indices, ]
classification_tree <- rpart(
customer_segment ~ purchase_frequency + total_quantity + avg_discount + preferred_payment + preferred_category,
data = train_data,
method = "class"
)
summary(classification_tree)
fancyRpartPlot(classification_tree)
predictions <- predict(classification_tree, test_data, type = "class")
test_data$predicted_segment <- predictions
confusion_matrix <- table(Actual = test_data$customer_segment, Predicted = test_data$predicted_segment)
print(confusion_matrix)
<<<<<<< Updated upstream
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_segment),    # Predicted values
reference = as.factor(test_data$customer_segment) # Actual values
)
# Print the confusion matrix
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
predicted_probs <- predict(classification_tree, test_data, type = "prob")
actual <- ifelse(test_data$customer_segment == "High", 1, 0)
predicted <- predicted_probs[, "High"]
thresholds <- seq(0, 1, by = 0.01)
tpr <- c()
fpr <- c()
=======
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
predicted_probs <- predict(classification_tree, test_data, type = "prob")
actual <- ifelse(test_data$customer_segment == "High", 1, 0) # Adjust for your "positive" class
predicted <- predicted_probs[, "High"]
thresholds <- seq(0, 1, by = 0.01)
tpr <- c()  # True Positive Rate
fpr <- c()  # False Positive Rate
>>>>>>> Stashed changes
for (threshold in thresholds) {
predicted_class <- ifelse(predicted >= threshold, 1, 0)
tp <- sum(predicted_class == 1 & actual == 1)
fp <- sum(predicted_class == 1 & actual == 0)
fn <- sum(predicted_class == 0 & actual == 1)
tn <- sum(predicted_class == 0 & actual == 0)
<<<<<<< Updated upstream
tpr <- c(tpr, tp / (tp + fn))
fpr <- c(fpr, fp / (fp + tn))
=======
tpr <- c(tpr, tp / (tp + fn)) # Sensitivity
fpr <- c(fpr, fp / (fp + tn)) # 1 - Specificity
>>>>>>> Stashed changes
}
plot(fpr, tpr, type = "l", col = "blue", lwd = 2, xlab = "False Positive Rate", ylab = "True Positive Rate",
main = "ROC Curve")
abline(a = 0, b = 1, col = "red", lty = 2)
<<<<<<< Updated upstream
sortedindices = order(fpr)
fpr = fpr[sortedindices]
tpr = tpr[sortedindices]
auc = sum((fpr[-1] - fpr[-length(fpr)]) * (tpr[-1] + tpr[-length(tpr)]) / 2)
cat("AUC:",auc, "\n")
logistic_data <- cleaned_data %>%
mutate(
SalesChannel = ifelse(SalesChannel == "Online", 1, 0)
) %>%
select(
SalesChannel, CustomerID, Quantity, UnitPrice, Discount, OrderPriority, Country, PaymentMethod
)
=======
auc <- sum((fpr[-1] - fpr[-length(fpr)]) * (tpr[-1] + tpr[-length(tpr)]) / 2)
cat("AUC:", auc, "\n")
>>>>>>> Stashed changes
set.seed(123)
train_indices <- sample(1:nrow(logistic_data), 0.7 * nrow(logistic_data))
train_data <- logistic_data[train_indices, ]
test_data <- logistic_data[-train_indices, ]
logistic_model <- glm(
SalesChannel ~ Quantity + UnitPrice + Discount + OrderPriority + Country + PaymentMethod,
data = train_data,
family = "binomial"
)
summary(logistic_model)
logistic_model$coefficients
predicted_probabilities <- predict(logistic_model, test_data, type = "response")
test_data$predicted_channel <- ifelse(predicted_probabilities > 0.5, 1, 0)
predicted_probabilities <- predict(logistic_model, test_data, type = "response")
# Convert probabilities to binary predictions based on a threshold (e.g., 0.5)
test_data$predicted_channel <- ifelse(predicted_probabilities > 0.5, 1, 0)
# Create confusion matrix using caret
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_channel),     # Predicted values
reference = as.factor(test_data$SalesChannel)      # Actual values
# Load necessary libraries
library(caret)
# Predict probabilities on the test data
predicted_probabilities <- predict(logistic_model, newdata = test_data, type = "response")
# Convert probabilities to binary predictions (threshold = 0.5)
predicted_class <- ifelse(predicted_probabilities > 0.5, 1, 0)
# Add predictions to the test data for reference
test_data$predicted_sales_channel <- predicted_class
# Create a confusion matrix using caret
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_sales_channel),   # Predicted values
reference = as.factor(test_data$SalesChannel)         # Actual values
)
# Print the confusion matrix
print(confusion_matrix)
<<<<<<< Updated upstream
predicted_probs_log <- predict(logistic_model, test_data, type = "response")
actual_log <- test_data$SalesChannel
roc_log <- roc(actual_log, predicted_probs_log)
plot(roc_log, col = "green", lwd = 2, main = "ROC Curve: Logistic Regression")
abline(a = 0, b = 1, col = "red", lty = 2)
cat("AUC for Logistic Regression:", auc(roc_log), "\n")
predicted_probs_log <- predict(logistic_model, test_data, type = "response")
actual_log <- test_data$SalesChannel
roc_log <- roc(actual_log, predicted_probs_log)
plot(roc_log, col = "green", lwd = 2, main = "ROC Curve: Logistic Regression")
abline(a = 0, b = 1, col = "red", lty = 2)
cat("AUC for Logistic Regression:", auc(roc_log), "\n")
predicted_probs = predict(logistic_model, test_data, type = "response")
roc_curve= roc(test_data$SalesChannel, predicted_probabilities)
plot(roc_curve, col = "blue", lwd = 2, main = "ROC Curve")
abline(a = 0, b = 1, col = "red", lty = 2)
auc_value = auc(roc_curve)
cat("AUC:", auc_value, "\n")
predicted_probabilities <- predict(logistic_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predicted_probabilities > 0.5, 1, 0)
test_data$predicted_sales_channel <- predicted_class
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_sales_channel),
reference = as.factor(test_data$SalesChannel))
print(confusion_matrix)
predicted_probs = predict(logistic_model, test_data, type = "response")
roc_curve= roc(test_data$SalesChannel, predicted_probabilities)
plot(roc_curve, col = "blue", lwd = 2, main = "ROC Curve")
abline(a = 0, b = 1, col = "red", lty = 2)
auc_value = auc(roc_curve)
cat("AUC:", auc_value, "\n")
predicted_probabilities <- predict(logistic_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predicted_probabilities > 0.5, 1, 0)
test_data$predicted_sales_channel <- predicted_class
confusion_matrix2 <- confusionMatrix(
data = as.factor(test_data$predicted_sales_channel),
reference = as.factor(test_data$SalesChannel))
print(confusion_matrix2)
accuracy <- sum(diag(confusion_matrix2)) / sum(confusion_matrix2)
accuracy <- confusion_matrix2$overall["Accuracy"]
print(accuracy)
accuracy <- confusion_matrix2$overall["Accuracy"]
cat("Accuracy:", accuracy, "\n")
sales_data <- cleaned_data %>%
group_by(StockCode, OrderPriority, CustomerID) %>%
summarise(
avg_discount = mean(Discount, na.rm = TRUE),
total_sales_revenue = sum(UnitPrice * Quantity, na.rm = TRUE),
total_quantity_sold = sum(Quantity, na.rm = TRUE),
.groups = "drop"
)
customer_data <- cleaned_data %>%
select(CustomerID, Country, PaymentMethod) %>%
distinct(CustomerID, .keep_all = TRUE)
sales_data <- sales_data %>%
left_join(customer_data, by = "CustomerID")
cor_matrix <- cor(sales_data %>% select(avg_discount, total_sales_revenue, total_quantity_sold))
corrplot(
cor_matrix,
method = "color",
type = "upper",
addCoef.col = "black",
tl.col = "black",
col = colorRampPalette(c("red", "white", "purple"))(200))
set.seed(123)
train_indices1 <- sample(1:nrow(sales_data), 0.7 * nrow(sales_data))
train_data1 <- sales_data[train_indices1, ]
test_data1 <- sales_data[-train_indices1, ]
lm_sales_model <- lm(
total_sales_revenue ~ avg_discount + OrderPriority + PaymentMethod + total_quantity_sold,
data = train_data1)
summary(lm_sales_model)
lm_sales_model$coefficients
fitted_values <- lm_sales_model$fitted.values
residuals <- train_data1$total_sales_revenue - fitted_values
MAE <- mean(abs(residuals))
RMSE <- sqrt(mean(residuals^2))
SS_total <- sum((train_data1$total_sales_revenue - mean(train_data1$total_sales_revenue))^2)
SS_residual <- sum(residuals^2)
R_squared <- 1 - (SS_residual / SS_total)
n <- nrow(train_data1)
p <- length(coef(lm_sales_model)) - 1
Adjusted_R_squared <- 1 - ((1 - R_squared) * (n - 1)) / (n - p - 1)
cat("MAE:", MAE, "\n")
cat("RMSE:", RMSE, "\n")
cat("R-squared:", R_squared, "\n")
cat("Adjusted R-squared:", Adjusted_R_squared, "\n")
regression_tree <- rpart(
total_sales_revenue ~ avg_discount + OrderPriority + PaymentMethod + total_quantity_sold,data = train_data1,method="anova")
summary(regression_tree)
fancyRpartPlot(regression_tree)
residuals_tree <- test_data1$total_sales_revenue - predict(regression_tree, test_data1)
MAE_tree <- mean(abs(residuals_tree))
RMSE_tree <- sqrt(mean(residuals_tree^2))
SS_total_tree <- sum((test_data1$total_sales_revenue - mean(test_data1$total_sales_revenue))^2)
SS_residual_tree <- sum(residuals_tree^2)
R_squared_tree <- 1 - (SS_residual_tree / SS_total_tree)
n <- nrow(test_data1)  # number of data points
p <- length(coef(regression_tree))  # number of predictors
Adjusted_R_squared_tree <- 1 - ((1 - R_squared_tree) * (n - 1)) / (n - p - 1)
cat("MAE (Tree):", MAE_tree, "\n")
cat("RMSE (Tree):", RMSE_tree, "\n")
cat("R-squared (Tree):", R_squared_tree, "\n")
cat("Adjusted R-squared (Tree):", Adjusted_R_squared_tree, "\n")
customer_data <- cleaned_data %>%
group_by(CustomerID) %>%
summarize(
purchase_frequency = n_distinct(InvoiceNo),
total_quantity = sum(Quantity, na.rm = TRUE),
total_spend = sum(UnitPrice * Quantity, na.rm = TRUE),
avg_discount = mean(Discount, na.rm = TRUE),
preferred_payment = as.character(names(sort(table(PaymentMethod), decreasing = TRUE)[1])),
preferred_category = as.character(names(sort(table(Category), decreasing = TRUE)[1]))
)
spend_summary <- summary(customer_data$total_spend)
low_threshold <- spend_summary["1st Qu."]
high_threshold <- spend_summary["3rd Qu."]
customer_data <- customer_data %>%
mutate(
customer_segment = case_when(
total_spend < low_threshold ~ "Low",
total_spend >= low_threshold & total_spend < high_threshold ~ "Medium",
total_spend >= high_threshold ~ "High"
)
)
customer_data$preferred_payment <-  as.factor(customer_data$preferred_payment)
customer_data$preferred_category <- as.factor(customer_data$preferred_category)
customer_data$preferred_payment <- as.numeric(customer_data$preferred_payment)
customer_data$preferred_category <- as.numeric(customer_data$preferred_category)
cor_matrix <- cor(customer_data %>%
select(purchase_frequency, total_quantity, avg_discount, preferred_payment, preferred_category),
use = "complete.obs")
corrplot(
cor_matrix,
method = "color",
type = "upper",
addCoef.col = "black",
tl.col = "black",
col = colorRampPalette(c("red", "white", "purple"))(200),
mar = c(0, 0, 1, 0))
set.seed(123)
train_indices <- sample(1:nrow(customer_data), 0.7 * nrow(customer_data))
train_data <- customer_data[train_indices, ]
test_data <- customer_data[-train_indices, ]
classification_tree <- rpart(
customer_segment ~ purchase_frequency + total_quantity + avg_discount + preferred_payment + preferred_category,
data = train_data,
method = "class"
)
summary(classification_tree)
fancyRpartPlot(classification_tree)
predictions <- predict(classification_tree, test_data, type = "class")
test_data$predicted_segment <- predictions
confusion_matrix <- confusionMatrix(
data = as.factor(test_data$predicted_segment),
reference = as.factor(test_data$customer_segment))
print(confusion_matrix)
cat("Accuracy:", confusion_matrix$overall["Accuracy"], "\n")
predicted_probs <- predict(classification_tree, test_data, type = "prob")
actual <- ifelse(test_data$customer_segment == "High", 1, 0)
predicted <- predicted_probs[, "High"]
thresholds <- seq(0, 1, by = 0.01)
tpr <- c()
fpr <- c()
for (threshold in thresholds) {
predicted_class <- ifelse(predicted >= threshold, 1, 0)
tp <- sum(predicted_class == 1 & actual == 1)
fp <- sum(predicted_class == 1 & actual == 0)
fn <- sum(predicted_class == 0 & actual == 1)
tn <- sum(predicted_class == 0 & actual == 0)
tpr <- c(tpr, tp / (tp + fn))
fpr <- c(fpr, fp / (fp + tn))
}
plot(fpr, tpr, type = "l", col = "blue", lwd = 2, xlab = "False Positive Rate", ylab = "True Positive Rate",
main = "ROC Curve")
abline(a = 0, b = 1, col = "red", lty = 2)
sortedindices = order(fpr)
fpr = fpr[sortedindices]
tpr = tpr[sortedindices]
auc = sum((fpr[-1] - fpr[-length(fpr)]) * (tpr[-1] + tpr[-length(tpr)]) / 2)
cat("AUC:",auc, "\n")
logistic_data <- cleaned_data %>%
mutate(
SalesChannel = ifelse(SalesChannel == "Online", 1, 0)
) %>%
select(
SalesChannel, CustomerID, Quantity, UnitPrice, Discount, OrderPriority, Country, PaymentMethod)
logistic_data <- cleaned_data %>%
mutate(
SalesChannel = ifelse(SalesChannel == "Online", 1, 0)
) %>%
select(
SalesChannel, CustomerID, Quantity, UnitPrice, Discount, OrderPriority, PaymentMethod)
set.seed(123)
train_indices <- sample(1:nrow(logistic_data), 0.7 * nrow(logistic_data))
train_data <- logistic_data[train_indices, ]
test_data <- logistic_data[-train_indices, ]
logistic_model <- glm(
SalesChannel ~ Quantity + UnitPrice + Discount + OrderPriority + PaymentMethod,
data = train_data,
family = "binomial"
)
summary(logistic_model)
predicted_probabilities <- predict(logistic_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predicted_probabilities > 0.5, 1, 0)
test_data$predicted_sales_channel <- predicted_class
confusion_matrix2 <- confusionMatrix(
data = as.factor(test_data$predicted_sales_channel),
reference = as.factor(test_data$SalesChannel))
print(confusion_matrix2)
logistic_model$coefficients
predicted_probabilities <- predict(logistic_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predicted_probabilities > 0.5, 1, 0)
test_data$predicted_sales_channel <- predicted_class
confusion_matrix2 <- confusionMatrix(
data = as.factor(test_data$predicted_sales_channel),
reference = as.factor(test_data$SalesChannel))
print(confusion_matrix2)
=======
performance <- confusionMatrix(factor(test_data$predicted_channel), factor(test_data$SalesChannel))
accuracy <- performance$overall["Accuracy"]
print(accuracy)
thresholds <- seq(0, 1, by = 0.01)
# Initialize vectors to store TPR and FPR values for each threshold
tpr <- numeric(length(thresholds))
fpr <- numeric(length(thresholds))
# Loop over each threshold to calculate TPR and FPR
for (i in 1:length(thresholds)) {
threshold <- thresholds[i]
# Predicted labels: 1 if predicted probability is greater than the threshold, else 0
predicted_labels <- ifelse(predicted_probabilities > threshold, 1, 0)
# Create confusion matrix
confusion <- table(Predicted = predicted_labels, Actual = actual_values)
# Ensure the confusion matrix has all the required values (TP, FP, FN, TN)
tp <- confusion["1", "1"]  # True Positive
tn <- confusion["0", "0"]  # True Negative
fp <- confusion["0", "1"]  # False Positive
fn <- confusion["1", "0"]  # False Negative
# If any value is missing, set it to 0
tp <- ifelse(is.na(tp), 0, tp)
tn <- ifelse(is.na(tn), 0, tn)
fp <- ifelse(is.na(fp), 0, fp)
fn <- ifelse(is.na(fn), 0, fn)
# Calculate True Positive Rate (TPR) = TP / (TP + FN), handling zero division
tpr[i] <- ifelse((tp + fn) != 0, tp / (tp + fn), 0)
# Calculate False Positive Rate (FPR) = FP / (FP + TN), handling zero division
fpr[i] <- ifelse((fp + tn) != 0, fp / (fp + tn), 0)
}
>>>>>>> Stashed changes
