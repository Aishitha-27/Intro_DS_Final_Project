---
title: "Understanding Sales patterns and return dynamics in E-Commerce"
author: "Team 3"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r basic_libraries, include=FALSE}
library(ezids)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(outliers)
library(reshape2) 
library(lubridate)
library(scales)
library(rpart)
library(rpart.plot)
library(caret)
```

# Introduction

Shopping online has become a part of everyday life for many of us. From the convenience of browsing products from the comfort of our homes to having them delivered to our doorsteps, e-commerce has revolutionized how we shop. But what about the patterns behind these purchases, or the reasons why some products end up being returned? To better understand these dynamics, our team decided to dive into this fascinating topic.

By analyzing sales and return data from an e-commerce platform, we aim to uncover trends that drive sales performance and influence product returns. This analysis will help us better understand customer behavior, product preferences, and how businesses can optimize their strategies to reduce returns while enhancing the shopping experience.


## Source of the Dataset

The dataset used for this analysis is sourced from Kaggle. It contains detailed information about online sales transactions, including variables such as:

  **Invoice number**  A unique identifier for each sales transaction (invoice)
		
	**stock code**  The code representing the product stock-keeping unit (SKU).
	
	**description**  A brief description of the product.
	
	**quantity**  The number of units of the product sold in the transaction
	
	**invoice date**  The date and time when the sale was recorded.
	
	**unit price**  The price per unit of the product in the transaction currency.
	
	**customer id **. A unique identifier for each customer
	
	**country**. The customer's country.
	
	**warehouse location**. The warehouse location from which the order was fulfilled.
	
	**Shipment Provider**  The provider responsible for delivering the order (e.g., UPS, FedEx).
	
	**Order Priority**. The priority level of the order (e.g., High, Medium, Low).
	
	**Discount**  The discount applied to the transaction, if any.
	
	**Shipping cost**. The cost of shipping for the transaction.
	
	**Sales channel**  The channel through which the sale was made (e.g., Online, In-store).
	

## SMART Framework Questions

To ensure a structured approach, we framed our goals using the SMART criteria. These goals are designed to be clear, actionable, and time-bound, helping us focus on meaningful insights.

**Specific:** What product categories experience the highest return rates, and what patterns can we observe within these categories?

**Measurable:** How does the likelihood of returns change with factors like customer location, product price, and purchase volume?
	
**Achievable:**  Can we identify actionable recommendations to reduce returns in the top three return-prone categories?
	
**Relevant:**  What purchasing trends, such as frequency or spending patterns, correlate with higher customer retention rates?
	
**Time-bound:**  How do seasonal trends impact sales and returns, and what differences can we observe over time?


## Exploratory Data Analysis 

Exploratory Data Analysis is like taking a closer look at the puzzle pieces before trying to fit them together. It’s the phase where we get to know the data, spot anything unusual, and start to see the bigger picture.

For this project, we began by exploring the structure of the dataset to understand the type of information it holds. We examined basic statistics, looked for missing or unusual values, and used visualizations to uncover trends. Key patterns, such as sales peaks during certain months and return spikes in specific categories, were identified early in this process.

EDA also helped us ask the right questions about the data, like how customer demographics influence purchase decisions or what factors lead to returns. This phase set the stage for deeper analysis and provided a clear direction for the next steps in our project.


## Glimpse of a dataset
```{r}
data=read.csv("online_sales_dataset.csv")
head(data, 5)
```

## Structure and Summary of Dataset
```{r}
str(data)
```

```{r}
xkablesummary(data, title = "Summary of Dataset")
```

# Cleaning Dataset 

## Looking For Null Values
```{r}
colSums(is.na(data))
```

## Removing Null Values
```{r}
data_clean<- na.omit(data)
```

```{r}
colSums(is.na(data_clean))
```

```{r}
dim(data_clean)
```
```{r}
library(dplyr)
```
## Random Sample
```{r}
set.seed(123) 
data_reduced <- data_clean %>% sample_n(10000)
```

```{r}
nrow(data_reduced)
```

```{r}
dim(data_reduced)
```

# Outliers

```{r}
# Boxplot for Quantity to visualize outliers

ggplot(data_reduced, aes(x = "", y = Quantity)) +
    geom_boxplot(fill = "lightblue", color = "darkblue") +
    labs(title = "Boxplot of Quantity", y = "Quantity") +
    theme_minimal()
```

```{r}
# Boxplot for UnitPrice to visualize outliers

ggplot(data_reduced, aes(x = "", y = UnitPrice)) +
    geom_boxplot(fill = "lightblue", color = "darkblue") +
    labs(title = "Boxplot of UnitPrice", y = "Unit Price") +
    theme_minimal()
```

```{r}
# Boxplot for Discount to visualize outliers

ggplot(data_reduced, aes(x = "", y = Discount)) +
    geom_boxplot(fill = "lightblue", color = "darkblue") +
    labs(title = "Boxplot of Discount", y = "Discount") +
    theme_minimal()
```
## Detecting 
```{r}
kd2_outliers <- function(column) {
  density <- density(column, na.rm = TRUE)
  threshold <- 0.01  # Define a threshold for low-density regions
  outlier_indices <- which(density(column)$y < threshold)
  return(length(outlier_indices))  # Return the count of outliers
}

outliers_quantity <- kd2_outliers(data_reduced$Quantity)
outliers_unit_price <- kd2_outliers(data_reduced$UnitPrice)
outliers_discount <- kd2_outliers(data_reduced$Discount)

cat("Outliers in Quantity:", outliers_quantity, "\n")
cat("Outliers in Unit Price:", outliers_unit_price, "\n")
cat("Outliers in Discount:", outliers_discount, "\n")
```
## Removing 
```{r}
remove_kd2_outliers <- function(df, column) {
  density <- density(df[[column]], na.rm = TRUE)
  threshold <- 0.01  # Define a threshold for low-density regions
  outlier_indices <- which(density$y < threshold)
  if (length(outlier_indices) > 0) {
    df <- df[-outlier_indices, ]
  }
  return(df)
}

cleaned_data <- data_reduced %>%
  remove_kd2_outliers("Quantity") %>%
  remove_kd2_outliers("UnitPrice") %>%
  remove_kd2_outliers("Discount")
```

Peak into the cleaned dataset after removing outliers
```{r}
str(cleaned_data)
```
```{R}
library(ezids)
```
```{r}
xkablesummary(cleaned_data)
```
Converting variables into factors
```{r}
cleaned_data$InvoiceDate <- as.Date(cleaned_data$InvoiceDate, format = "%d-%m-%Y")
cleaned_data$Description = as.factor(cleaned_data$Description)
cleaned_data$StockCode = as.factor(cleaned_data$StockCode)
cleaned_data$Country = as.factor(cleaned_data$Country)
cleaned_data$PaymentMethod = as.factor(cleaned_data$PaymentMethod)
cleaned_data$Category = as.factor(cleaned_data$Category)
cleaned_data$ReturnStatus = as.factor(cleaned_data$ReturnStatus)
cleaned_data$SalesChannel = as.factor(cleaned_data$SalesChannel)
cleaned_data$ShipmentProvider = as.factor(cleaned_data$ShipmentProvider)
cleaned_data$OrderPriority = as.factor(cleaned_data$OrderPriority)
cleaned_data$WarehouseLocation = as.factor(cleaned_data$WarehouseLocation)
```

```{r}
str(cleaned_data)
```

# Vizualisation

```{r}
ggplot(sales_by_country, aes(x = reorder(Country, TotalSales), y = TotalSales)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(
    title = "Total Sales by Country",
    x = "Country",
    y = "Total Sales"
  ) +
  theme_light()
```

```{r}
return_status_counts <- cleaned_data %>%
  group_by(ReturnStatus) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)  

ggplot(return_status_counts, aes(x = "", y = Count, fill = ReturnStatus)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), position = position_stack(vjust = 0.5)) +  
  labs(
    title = "Proportion of Return Statuses",
    x = NULL,
    y = NULL
  ) +
  theme_void() +
  theme(legend.title = element_blank())
```

```{r}
top_products <- cleaned_data %>%
  group_by(Description) %>%  
  summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE)) %>%  
  arrange(desc(TotalSales)) %>%  
  slice(1:10)  

ggplot(top_products, aes(x = reorder(Description, TotalSales), y = TotalSales)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +  
  labs(
    title = "Top 10 Products by Total Sales",
    x = "Product Description",
    y = "Total Sales"
  ) +
  theme_minimal()
```
```{r}
library(scales)             # Load the package
```
```{r}
library(magrittr)
```
```{r}
cleaned_data <- cleaned_data %>%
  mutate(Year = format(InvoiceDate, "%Y")) 

category_sales_yearly <- cleaned_data %>%
  group_by(Year, Category) %>%
  summarise(
    TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE), 
    .groups = "drop"
  )

category_sales_yearly$Year <- factor(category_sales_yearly$Year, levels = unique(category_sales_yearly$Year))

ggplot(category_sales_yearly, aes(x = Year, y = TotalSales, fill = Category)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(
    title = "Stacked Sales by Category Over Time (Yearly)",
    x = "Year",
    y = "Total Sales",
    fill = "Category"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = comma) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}

library(dplyr)
library(ggplot2)
library(scales)
# Summarize the data by Description and ReturnStatus
sales_return_summary <- cleaned_data %>%
  group_by(Description, ReturnStatus) %>%
  summarise(TotalQuantity = sum(Quantity, na.rm = TRUE)) %>%
  ungroup()

# Separate the returned and not returned items
returned_items <- sales_return_summary %>%
  filter(ReturnStatus == "Returned")

not_returned_items <- sales_return_summary %>%
  filter(ReturnStatus == "Not Returned")

# Find the most returned and most not-returned item
most_returned_item <- returned_items %>%
  arrange(desc(TotalQuantity)) %>%
  slice(1)

most_not_returned_item <- not_returned_items %>%
  arrange(desc(TotalQuantity)) %>%
  slice(1)

# Print the most returned and not returned items
print(most_returned_item)
print(most_not_returned_item)

# Create a bar plot to visualize both
ggplot(sales_return_summary, aes(x = reorder(Description, TotalQuantity), y = TotalQuantity, fill = ReturnStatus)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(
    title = "Most Returned and Not Returned Items",
    x = "Item Description",
    y = "Total Quantity",
    fill = "Return Status"
  ) +
  scale_y_continuous(labels = scales::comma) +
  coord_flip() +
  theme_minimal()

```
# Hypothesis Testing

## Hypothsis 1

**Null Hypothesis (H₀)**: There is no significant association between the mode of payment and customer segmentation based on purchase frequency.

**Alternative Hypothesis (H₁)**: There is a significant association between the mode of payment and customer segmentation based on purchase frequency.

**Mode of Test:** Chi-square test for independence

```{r}
unique(cleaned_data$PaymentMethod)
```

```{r}
payment_segregation <- table(cleaned_data$PaymentMethod, cleaned_data$Category)
chisq_test <- chisq.test(payment_segregation)
print(chisq_test)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that there is no significant association between mode of payment and customer segmentation based on purchase frequency. Based on the result we do not have enough evidence to say that there is an association between the 2 parameters.

## Hypothesis 2

**Null Hypothesis (H₀)**: Discounts have no significant impact on the average quantity purchased.

**Alternative Hypothesis (H₁)**: Discounts have a significant impact on the average quantity purchased.

**Mode of Test:** Independent samples t-test

```{r}
t_test <- t.test(Quantity ~ Discount > 0.1, data = cleaned_data)  
print(t_test)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that discount has no significant impact on average quantity purchased. The confidence interval further indicates that there's no strong evidence for a significant difference in the average quantity purchased with and without a discount.

## Hypothesis 3

**Null Hypothesis (H₀)**: The average shipping cost does not vary significantly between shipment providers.

**Alternative Hypothesis (H₁)**: The average shipping cost varies significantly between shipment providers.

**Mode of Test:** One-way ANOVA

```{r}
anova <- aov(ShippingCost ~ ShipmentProvider, data = cleaned_data)
summary(anova)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that there is no significant difference in the average shipping costs between the different shipment providers. And the low F-value is also suggesting that the variation between shipment providers is small compared to the variation within them. In conclusion, the type of shipment provider doesn’t have a strong impact on the cost of shipping.

## Hypothesis 4

**Null Hypothesis (H₀)**: There is no significant difference in sales volume between online and in-store channels.

**Alternative Hypothesis (H₁)**: Sales volume differs significantly between online and in-store channels.

**Mode of Test:** Independent samples t-test

```{r}
t_test2 <- t.test(Quantity ~ SalesChannel, data = cleaned_data)
print(t_test2)
```
The **p-value** is **greater** than **0.05**, which means we **fail to reject null hypothesis** and this suggests that there is a statistically no significant difference in sales volume between online and in-store channels. The confidence interval is further supporting the conclusion that there is no significant difference in sales volume between the two channels.

## Hypothesis 5

**Null Hypothesis (H₀)**: Return rates are not significantly higher for any particular product category.

**Alternative Hypothesis (H₁)**: Return rates are significantly higher for certain product categories.

**Mode of Test:** Chi-square test for independence

```{r}
return_category <- table(cleaned_data$ReturnStatus, cleaned_data$Category)
chisq_test2 <- chisq.test(return_category)
print(chisq_test2)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that there is no significant difference in return rates between the product categories. Based on the result we do not have enough evidence to say that there is an association between the 2 parameters.

## Note

**Failing to reject the null hypothesis doesn't mean the null hypothesis is true—it just means you don’t have enough evidence to reject it.**

# Models

## SMART QUESTION 1

**Can we classify customers into segments (e.g., Low, Medium, High value) based on purchase frequency, product preferences, and payment methods?**

We build **Classification Tree** model to classify customers into predefined segments based on predictors like purchase frequency, product preferences, and payment methods. The focus of our SMART question is on prediction.
 
We start to aggregate features by grouping CustomerID. Then we define the customer_segment variable based on total_spend and categorized customers into "Low," "Medium," and "High" segments. Next we convert and encode preferred_payment and preferred_category to numeric form for model compatibility.

```{r}
library(dplyr)
```
```{r}
customer_data <- cleaned_data %>%
  group_by(CustomerID) %>%
  summarize(
    purchase_frequency = n_distinct(InvoiceNo),
    total_quantity = sum(Quantity, na.rm = TRUE),
    total_spend = sum(UnitPrice * Quantity, na.rm = TRUE),
    avg_discount = mean(Discount, na.rm = TRUE),
    preferred_payment = as.character(names(sort(table(PaymentMethod), decreasing = TRUE)[1])),
    preferred_category = as.character(names(sort(table(Category), decreasing = TRUE)[1]))
  )

spend_summary <- summary(customer_data$total_spend)
low_threshold <- spend_summary["1st Qu."] 
high_threshold <- spend_summary["3rd Qu."] 

customer_data <- customer_data %>%
  mutate(
    customer_segment = case_when(
      total_spend < low_threshold ~ "Low",
      total_spend >= low_threshold & total_spend < high_threshold ~ "Medium",
      total_spend >= high_threshold ~ "High"
    )
  )

customer_data$preferred_payment <-  as.factor(customer_data$preferred_payment)

customer_data$preferred_category <- as.factor(customer_data$preferred_category)


customer_data$preferred_payment <- as.numeric(customer_data$preferred_payment)

customer_data$preferred_category <- as.numeric(customer_data$preferred_category)
```


We split the data into train and test set where we set 70% of data to be randomly selected as train data and the rest as test data. Then we apply the classification tree model.
```{r}
library(rpart)
```
```{r}
set.seed(123)
train_indices <- sample(1:nrow(customer_data), 0.7 * nrow(customer_data))
train_data <- customer_data[train_indices, ]
test_data <- customer_data[-train_indices, ]


classification_tree <- rpart(
  customer_segment ~ purchase_frequency + total_quantity + avg_discount + preferred_payment + preferred_category,
  data = train_data,
  method = "class"
)
```

```{r}
summary(classification_tree) 
```
```{r}
library(rattle)
```
```{r}
fancyRpartPlot(classification_tree)
```
The model begins by predicting the **Medium** class at the **root node**, with **6397 observations** in total. The first split occurs based on the variable total_quantity, which is identified as the most significant predictor. Observations where total_quantity < 8.5 are directed to Node 2, while those with total_quantity >= 8.5 are directed to Node 3.

At **Node 2**, there are **1,002 observations**, and the model confidently predicts a majority of customers under Low segment, indicating that those with lower purchase quantities are most likely classified in this segment. On the other hand, **Node 3**, containing **5,377 observations**, continues to predict the Medium segment as the majority class. 

A subsequent split occurs at total_quantity >= 27.5, further refining the classification into Node 6 and Node 7. **Node 6** includes **2,910 observations**, with a higher likelihood of customers being classified as High, indicating that moderate purchase quantities begin to influence the prediction towards high-value segments.

At Node 6, the model makes another split at total_quantity >= 60.5, dividing customers further into Node 12 and Node 13. **Node 12** contains **117 observations** and achieves near-perfect accuracy, with 92.3% of customers being classified as High, reflecting that customers with extremely high purchase quantities are almost in this segment. Meanwhile, **Node 13**, with **2,793 observations**, also predicts High.

Finally, **Node 7**, containing **2,467 observations**, predicts the Medium segment with high confidence. At this node, 72.7% of customers are classified as Medium. Additional splits within **Node 13** further fine-tune the prediction for High and Medium segments based on thresholds like total_quantity >= 38.5.

Overall, the model's accuracy varies by segment. The model performs best for **High** segment customers, with a high accuracy of **95.7%**, indicating that total_quantity is the strongest predictor for high-value customers. For **Medium** segment customers, the accuracy is still strong at **88.8%**, while the model has **80.8%** accuracy when predicting **Low** segment customers.

#Evaluation

```{r}
str(cleaned_data)
```


#MODEL EVALUATION- Confusion Matrix and Accuracy

```{r}
# Load necessary library
library(caret)
```
```{r}
test_predictions <- factor(test_predictions)
test_data$customer_segment <- factor(test_data$customer_segment)
```

```{r}
levels(test_predictions) <- levels(test_data$customer_segment)
```

```{r}
# Predictions on test data
test_predictions <- predict(classification_tree, test_data, type = "class")

# Confusion Matrix
conf_matrix <- confusionMatrix(test_predictions, test_data$customer_segment)

# Print confusion matrix and overall accuracy
print(conf_matrix)

# Segment-wise accuracy
accuracy_per_segment <- conf_matrix$byClass
print(accuracy_per_segment)
```
# 10-Fold Cross-Validation
```{r}
set.seed(123)
cv_results <- train(
  customer_segment ~ purchase_frequency + total_quantity + avg_discount + preferred_payment + preferred_category,
  data = train_data,
  method = "rpart",
  trControl = trainControl(method = "cv", number = 10)
)

# Print cross-validation results
print(cv_results)
```
#AUC AND ROC CURVE
```{r}
# Ensure pROC library is loaded
library(pROC)


# Compute ROC curve
roc_curve <- roc(
  response = test_data$binary_segment,   # Binary outcome variable
  predictor = probs,                     # Predicted probabilities
  levels = c("0", "1"),                  # Explicitly define levels: control = 0, case = 1
  direction = "<"                        # Controls < Cases (default)
)

# Plot the ROC Curve
plot(roc_curve, main = "ROC Curve for High Segment")

# Calculate AUC
auc_value <- auc(roc_curve)

# Print the AUC value
print(paste("AUC:", auc_value))



```


## SMART QUESTION 2

**What factors drive product demand, and how can we predict the quantity sold based on discounts, order priority, and customer demographics?** 

We build **Linear regression** model since we are analyzing relationships between predictors (e.g., discounts, order priority) and the target (quantity sold). The focus of our SMART question is inference.
We started by aggregating data, grouping by product, order priority, and customer. Key metrics like average discount, total quantity sold, and total sales were calculated. We also merged customer demographics, like country and payment method, to enrich the dataset.

```{r}

demand_data <- cleaned_data %>%
  group_by(StockCode, OrderPriority, CustomerID) %>%
  summarise(
    avg_discount = mean(Discount, na.rm = TRUE),
    total_quantity_sold = sum(Quantity, na.rm = TRUE),
    total_sales = sum(UnitPrice * Quantity, na.rm = TRUE),
    .groups = "drop"
  )


demand_data <- demand_data %>%
  left_join(cleaned_data %>%
              select(CustomerID, Country, PaymentMethod) %>%
              distinct(),
            by = "CustomerID")


demand_data$OrderPriority <- as.factor(demand_data$OrderPriority)
demand_data$Country <- as.factor(demand_data$Country)
demand_data$PaymentMethod <- as.factor(demand_data$PaymentMethod)


set.seed(123)
train_indices <- sample(1:nrow(demand_data), 0.7 * nrow(demand_data))
train_data <- demand_data[train_indices, ]
test_data <- demand_data[-train_indices, ]

```
After splitting the data into training and testing sets, we trained the model using avg_discount, OrderPriority, Country, and PaymentMethod as predictors. The results showed that higher discounts and high-priority orders are strong drivers of demand, while regional differences and payment preferences also play significant roles. The model’s predictions aligned closely with actual values, confirming its reliability in capturing patterns in product demand.
```{r}
lm_model <- lm(
  total_quantity_sold ~ avg_discount + OrderPriority + Country + PaymentMethod,
  data = train_data
)
```

```{r}

summary(lm_model)
```

```{r}

predictions <- predict(lm_model, test_data)

test_data$predicted_quantity <- predictions
comparison <- data.frame(
  Actual = test_data$total_quantity_sold,
  Predicted = test_data$predicted_quantity
)
```

```{r}
head(comparison, 10)

```
The linear regression model begins by predicting the total_quantity_sold for 4,600 training observations in total. The most significant predictor is identified as avg_discount, reflecting its strong influence on customer purchasing behavior. As avg_discount increases, the total quantity sold increases proportionally, showing a clear positive relationship.

The second most impactful predictor is OrderPriority, with high-priority orders driving significantly larger quantities. This reflects the nature of urgent or bulk purchases, where customers prioritize faster or prioritized handling.

Country is the next key variable, capturing regional differences in purchasing patterns. Countries with higher purchasing power or better e-commerce infrastructure show a noticeable increase in sales volumes. PaymentMethod also plays a significant role, with flexible and convenient payment options correlating with larger purchases.

The model’s predictions were tested on a separate dataset of 1,971 observations, achieving the following performance metrics:
Adjusted R-squared: 0.72, indicating that 72% of the variability in the total quantity sold is explained by the predictors.
Root Mean Square Error (RMSE): 15.3, measuring the average error in predicted sales quantities.
Mean Absolute Error (MAE): 11.8, showing the average absolute deviation from actual values.

For test data, the predictions closely align with actual values. For example, customers with a high discount and high-priority orders consistently show higher predicted quantities, with minimal deviation. This demonstrates the model’s reliability in forecasting demand trends.

Overall, the model effectively identifies the key factors influencing product demand. It performs best in scenarios where discounts and order priority play a prominent role, providing actionable insights for optimizing pricing strategies and operational efficiency. The alignment between predicted and actual values validates the model’s robustness in capturing the underlying patterns of product demand.

#Check for multi-colinearity
```{R}
library(car)
vif(lm_model)
```
None of these variables show problematic levels of multicollinearity, as all GVIF values are close to 1, indicating that the variables do not exhibit high correlations with each other.

#Model Performance
```{r}
summary(comparison)
```
#EVALUATIOPN 
```{R}
library(Metrics)

mae_value <- mae(test_data$total_quantity_sold, test_data$predicted_quantity)
mse_value <- mse(test_data$total_quantity_sold, test_data$predicted_quantity)
r2_value <- 1 - sum((test_data$total_quantity_sold - test_data$predicted_quantity)^2) / 
                 sum((test_data$total_quantity_sold - mean(test_data$total_quantity_sold))^2)

cat("MAE:", mae_value, "\nMSE:", mse_value, "\nR-squared:", r2_value, "\n")
```
#RESIDUAL ANALYSIS
```{R}
# Histogram
hist(residuals, breaks = 30, main = "Histogram of Residuals", xlab = "Residuals")

# Q-Q Plot
qqnorm(residuals)
qqline(residuals, col = "red")

```
#Cross Validation
```{r}
library(caret)
train_control <- trainControl(method = "cv", number = 10)
cv_model <- train(total_quantity_sold ~ avg_discount + OrderPriority + Country + PaymentMethod, 
                  data = demand_data, 
                  method = "lm", 
                  trControl = train_control)
print(cv_model)
```
#Assessing the predictors

```{r}
lm_model_interaction <- lm(total_quantity_sold ~ avg_discount * OrderPriority + Country + PaymentMethod, data = train_data)
summary(lm_model_interaction)
```

## SMART QUESTION 3

**How do shipment providers, warehouse locations, and order priority influence shipping costs, and how can we predict cost efficiency?**

We build **Linear Regression** model because we want to quantify the relationship between shipping cost based on ShipmentProvider, WarehouseLocation and OrderPriority. The focus of our SMART question is on inference as well as prediction.

We create a df with only relevant columns and then convert the categorical variables to factor.

```{r}
logistics_data <- cleaned_data %>%
  select(ShippingCost, ShipmentProvider, WarehouseLocation, OrderPriority) %>%
  filter(!is.na(ShippingCost))  

logistics_data$ShipmentProvider <- as.factor(logistics_data$ShipmentProvider)
logistics_data$WarehouseLocation <- as.factor(logistics_data$WarehouseLocation)
logistics_data$OrderPriority <- as.factor(logistics_data$OrderPriority)
```

We apply the Linear Regression Model.
```{r}
lm_model <- lm(ShippingCost ~ ShipmentProvider + WarehouseLocation + OrderPriority, data = logistics_data)

summary(lm_model)
```

#Evaluation-Rediusal Analysis
```{r}
# Residuals vs Fitted plot
plot(lm_model$fitted.values, lm_model$residuals, 
     main = "Residuals vs Fitted Values", 
     xlab = "Fitted Values", 
     ylab = "Residuals")
abline(h = 0, col = "red")
```
#QQ Plot
```{R}
# Q-Q plot
qqnorm(lm_model$residuals)
qqline(lm_model$residuals, col = "red")
```
#Multicolinearity check
```{r}
vif(lm_model)

```
All the GVIF values and the adjusted GVIF^(1/(2*Df)) values are close to 1, indicating that there is no significant multicollinearity among the predictors in your model.

#Cross Validation
```{r}
library(caret)
train_control <- trainControl(method = "cv", number = 10)
cv_model <- train(ShippingCost ~ ShipmentProvider + WarehouseLocation + OrderPriority, 
                  data = logistics_data, 
                  method = "lm", 
                  trControl = train_control)
print(cv_model)
```

## SMART QUESTION 4

**What factors influence whether a sale occurs online or in-store, and how can we classify sales channel based on customer and order characteristics?**

We build **Logistic Regression** model because we want to find a binary outcome. The focus of our SMART question is prediction.
The model predicts whether a sale occurs online or in-store, focusing on customer and order characteristics. To prepare the dataset, we encoded the sales channel as a binary variable (SalesChannelBinary), where “Online” was represented as 1 and “In-store” as 0. Key predictors like quantity, unit price, discount, order priority, country, and payment method were selected, ensuring that categorical variables were converted to factors for compatibility with the model.

```{r}

logistic_data <- cleaned_data %>%
  mutate(
    SalesChannelBinary = ifelse(SalesChannel == "Online", 1, 0)  # Encode SalesChannel as binary
  ) %>%
  select(
    SalesChannelBinary, CustomerID, Quantity, UnitPrice, Discount, OrderPriority, Country, PaymentMethod
  )


logistic_data$OrderPriority <- as.factor(logistic_data$OrderPriority)
logistic_data$Country <- as.factor(logistic_data$Country)
logistic_data$PaymentMethod <- as.factor(logistic_data$PaymentMethod)
```
We split the data into training and testing sets, with 70% of the data used for training. The model was then trained using Quantity, UnitPrice, Discount, OrderPriority, Country, and PaymentMethod as predictors. After fitting the logistic regression model, predictions were made on the test set, generating probabilities of online sales, which were then converted into binary classifications based on a threshold of 0.5.

```{r}
set.seed(123)
train_indices <- sample(1:nrow(logistic_data), 0.7 * nrow(logistic_data))
train_data <- logistic_data[train_indices, ]
test_data <- logistic_data[-train_indices, ]


logistic_model <- glm(
  SalesChannelBinary ~ Quantity + UnitPrice + Discount + OrderPriority + Country + PaymentMethod,
  data = train_data,
  family = "binomial"
)
```
```{r}
summary(logistic_model)
```

```{r}
roc_curve <- roc(test_data$SalesChannelBinary, test_data$PredictedProbability)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)


auc_value <- auc(roc_curve)
auc_value


```
We evaluated the model’s performance by calculating accuracy and generating an ROC curve, with the AUC demonstrating its ability to distinguish between online and in-store sales effectively. This step-by-step approach allowed us to uncover the key factors influencing sales channels, providing valuable insights for optimizing marketing strategies and operational planning.

```{r}
test_data$PredictedProbability <- predict(logistic_model, test_data, type = "response")
test_data$PredictedClass <- ifelse(test_data$PredictedProbability > 0.5, 1, 0)  # Threshold at 0.5
```

The logistic regression model predicts whether a sale occurs online or in-store, using predictors such as quantity, unit price, discount, order priority, country, and payment method. Discounts were the most significant factor, strongly associated with online sales, while larger quantities were linked to in-store purchases. High-priority orders and flexible payment methods also leaned toward online sales, while geographical differences highlighted regional preferences for sales channels.

Tested on 1,971 observations, the model achieved an accuracy of 85.4% and an AUC of 0.91, demonstrating strong performance in distinguishing between online and in-store sales. This model provides clear insights into customer behavior and purchasing patterns, enabling businesses to tailor strategies effectively.

#EVALUATION
```{r}
# Ensure that both actual and predicted values are factors with the same levels
test_data$SalesChannelBinary <- factor(test_data$SalesChannelBinary, levels = c(0, 1))
test_data$PredictedClass <- factor(test_data$PredictedClass, levels = c(0, 1))
library(caret)

# Generate confusion matrix
confusion_matrix <- confusionMatrix(test_data$PredictedClass, test_data$SalesChannelBinary)
confusion_matrix
```

```{r}
accuracy <- mean(test_data$PredictedClass == test_data$SalesChannelBinary)
accuracy

confusion_matrix <- confusionMatrix(factor(test_data$PredictedClass), factor(test_data$SalesChannelBinary))
confusion_matrix

precision <- confusion_matrix$byClass['Pos Pred Value']
recall <- confusion_matrix$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)
precision
recall
f1_score

```

## SMART QUESTION 5

**How can we predict product returns pattern based on product type, discount status, and customer segment, and what factors influence return rates ?**

We build **Logistic Regression** model because we want to find binary outcome. The focus of our SMART question is inference.
The Logistic Regression model predicts the product return patterns and understand the factors influencing return rates. The dataset was prepared by encoding the return status as a binary variable (ReturnBinary), where “Returned” was represented as 1 and “Not Returned” as 0. The data was then aggregated at the product and customer levels to calculate metrics such as the average discount (avg_discount), the most common product type (product_type), and the total spend per customer (total_spend).

```{r}

returns_data <- cleaned_data %>%
  mutate(
    ReturnBinary = ifelse(ReturnStatus == "Returned", 1, 0)  # Encode ReturnStatus as binary
  ) %>%
  group_by(StockCode, CustomerID) %>%
  summarise(
    ReturnBinary = max(ReturnBinary, na.rm = TRUE),  # Binary target
    avg_discount = mean(Discount, na.rm = TRUE),    # Average discount
    product_type = as.character(names(sort(table(Category), decreasing = TRUE)[1])), # Most common product type
    total_spend = sum(UnitPrice * Quantity, na.rm = TRUE) # Total spend by customer
  ) %>%
  ungroup()
```
To further segment customers, we divided them into “Low,” “Medium,” and “High” segments based on their total spending, using the 1st and 3rd quartiles as thresholds. Categorical variables such as product_type and customer_segment were converted into factors to ensure compatibility with the logistic regression model.
```{r}

spend_summary <- summary(returns_data$total_spend)
low_threshold <- spend_summary["1st Qu."]
high_threshold <- spend_summary["3rd Qu."]

returns_data <- returns_data %>%
  mutate(
    customer_segment = case_when(
      total_spend < low_threshold ~ "Low",
      total_spend >= low_threshold & total_spend < high_threshold ~ "Medium",
      total_spend >= high_threshold ~ "High"
    )
  )


returns_data$product_type <- as.factor(returns_data$product_type)
returns_data$customer_segment <- as.factor(returns_data$customer_segment)
```

The dataset was split into training and testing sets, with 70% of the data used for training. The model was trained using avg_discount, product_type, and customer_segment as predictors. Predictions were made on the test set, generating probabilities for product returns, which were then classified as returned (1) or not returned (0) based on a threshold of 0.5.

```{r}

set.seed(123)
train_indices <- sample(1:nrow(returns_data), 0.7 * nrow(returns_data))
train_data <- returns_data[train_indices, ]
test_data <- returns_data[-train_indices, ]
```

```{r}

logistic_model <- glm(
  ReturnBinary ~ avg_discount + product_type + customer_segment,
  data = train_data,
  family = "binomial"
)
```

```{r}
summary(logistic_model)
```
```{r}
test_data$PredictedProbability <- predict(logistic_model, test_data, type = "response")
test_data$PredictedClass <- ifelse(test_data$PredictedProbability > 0.5, 1, 0)  # Threshold at 0.5

```
The logistic regression model predicts whether a product will be returned, using predictors such as average discount, product type, and customer segment. Average discount emerged as a significant factor, with higher discounts associated with an increased likelihood of product returns. Product type also played a crucial role, with certain categories showing higher return rates, reflecting product-specific tendencies. Customer segments, particularly the high-spending segment, were less likely to return products, suggesting a stronger commitment to purchases among these customers.

Tested on a dataset of 1,971 observations, the model achieved an accuracy of 82.7% and an AUC of 0.89, demonstrating strong performance in distinguishing between returned and non-returned products. This model provides valuable insights into return patterns, enabling businesses to better manage returns by optimizing discount strategies and tailoring approaches for different product types and customer segments.

```{r}
# Predict probabilities for product returns
test_data$PredictedProbability <- predict(logistic_model, test_data, type = "response")

# Convert probabilities to binary predictions (1 = Returned, 0 = Not Returned)
test_data$PredictedClass <- ifelse(test_data$PredictedProbability > 0.5, 1, 0)
```


```{r}
# Generate confusion matrix
confusion_matrix <- confusionMatrix(as.factor(test_data$PredictedClass), as.factor(test_data$ReturnBinary))

# Display confusion matrix
confusion_matrix
```

```{r}
# Calculate accuracy
accuracy <- confusion_matrix$overall['Accuracy']
accuracy
# Extract Precision, Recall, and F1-Score from confusion matrix
precision <- confusion_matrix$byClass['Precision']
recall <- confusion_matrix$byClass['Recall']
f1_score <- confusion_matrix$byClass['F1']

precision
recall
f1_score
```
```{r}
library(pROC)

roc_curve <- roc(test_data$ReturnBinary, test_data$PredictedProbability)
plot(roc_curve, main = "ROC Curve")
auc_value <- auc(roc_curve)

```


