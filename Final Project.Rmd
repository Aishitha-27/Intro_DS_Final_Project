---
title: "Understanding Sales patterns and return dynamics in E-Commerce"
author: "Team 3"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r basic_libraries, include=FALSE}
library(ezids)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(outliers)
library(reshape2) 
library(lubridate)
library(scales)
library(rpart)
library(rpart.plot)
library(rattle)
```

# Introduction

## Source of the Dataset

## SMART Framework Questions

## Exploratory Data Analysis 

## Glimpse of a dataset
```{r}
data=read.csv("online_sales_dataset.csv")
head(data, 5)
```

## Structure and Summary of Dataset
```{r}
str(data)
```

```{r}
xkablesummary(data, title = "Summary of Dataset")
```

# Cleaning Dataset 

## Looking For Null Values
```{r}
colSums(is.na(data))
```

## Removing Null Values
```{r}
data_clean<- na.omit(data)
```

```{r}
colSums(is.na(data_clean))
```

```{r}
dim(data_clean)
```

## Random Sample
```{r}
set.seed(123) 
data_reduced <- data_clean %>% sample_n(10000)
```

```{r}
nrow(data_reduced)
```

```{r}
dim(data_reduced)
```

# Outliers

```{r}
# Boxplot for Quantity to visualize outliers

ggplot(data_reduced, aes(x = "", y = Quantity)) +
    geom_boxplot(fill = "lightblue", color = "darkblue") +
    labs(title = "Boxplot of Quantity", y = "Quantity") +
    theme_minimal()
```

```{r}
# Boxplot for UnitPrice to visualize outliers

ggplot(data_reduced, aes(x = "", y = UnitPrice)) +
    geom_boxplot(fill = "lightblue", color = "darkblue") +
    labs(title = "Boxplot of UnitPrice", y = "Unit Price") +
    theme_minimal()
```

```{r}
# Boxplot for Discount to visualize outliers

ggplot(data_reduced, aes(x = "", y = Discount)) +
    geom_boxplot(fill = "lightblue", color = "darkblue") +
    labs(title = "Boxplot of Discount", y = "Discount") +
    theme_minimal()
```
## Detecting 
```{r}
kd2_outliers <- function(column) {
  density <- density(column, na.rm = TRUE)
  threshold <- 0.01  # Define a threshold for low-density regions
  outlier_indices <- which(density(column)$y < threshold)
  return(length(outlier_indices))  # Return the count of outliers
}

outliers_quantity <- kd2_outliers(data_reduced$Quantity)
outliers_unit_price <- kd2_outliers(data_reduced$UnitPrice)
outliers_discount <- kd2_outliers(data_reduced$Discount)

cat("Outliers in Quantity:", outliers_quantity, "\n")
cat("Outliers in Unit Price:", outliers_unit_price, "\n")
cat("Outliers in Discount:", outliers_discount, "\n")
```
## Removing 
```{r}
remove_kd2_outliers <- function(df, column) {
  density <- density(df[[column]], na.rm = TRUE)
  threshold <- 0.01  # Define a threshold for low-density regions
  outlier_indices <- which(density$y < threshold)
  if (length(outlier_indices) > 0) {
    df <- df[-outlier_indices, ]
  }
  return(df)
}

cleaned_data <- data_reduced %>%
  remove_kd2_outliers("Quantity") %>%
  remove_kd2_outliers("UnitPrice") %>%
  remove_kd2_outliers("Discount")
```

Peak into the cleaned dataset after removing outliers
```{r}
str(cleaned_data)
```

```{r}
xkablesummary(cleaned_data)
```
Converting variables into factors
```{r}
cleaned_data$InvoiceDate <- as.Date(cleaned_data$InvoiceDate, format = "%d-%m-%Y")
cleaned_data$Description = as.factor(cleaned_data$Description)
cleaned_data$StockCode = as.factor(cleaned_data$StockCode)
cleaned_data$Country = as.factor(cleaned_data$Country)
cleaned_data$PaymentMethod = as.factor(cleaned_data$PaymentMethod)
cleaned_data$Category = as.factor(cleaned_data$Category)
cleaned_data$ReturnStatus = as.factor(cleaned_data$ReturnStatus)
cleaned_data$SalesChannel = as.factor(cleaned_data$SalesChannel)
cleaned_data$ShipmentProvider = as.factor(cleaned_data$ShipmentProvider)
cleaned_data$OrderPriority = as.factor(cleaned_data$OrderPriority)
cleaned_data$WarehouseLocation = as.factor(cleaned_data$WarehouseLocation)
```

```{r}
str(cleaned_data)
```

# Vizualisation

```{r}
sales_by_country <- cleaned_data %>%
  group_by(Country) %>%
  summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE))

ggplot(sales_by_country, aes(x = reorder(Country, TotalSales), y = TotalSales)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(
    title = "Total Sales by Country",
    x = "Country",
    y = "Total Sales"
  ) +
  theme_minimal()
```

```{r}
return_status_counts <- cleaned_data %>%
  group_by(ReturnStatus) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)  

ggplot(return_status_counts, aes(x = "", y = Count, fill = ReturnStatus)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), position = position_stack(vjust = 0.5)) +  
  labs(
    title = "Proportion of Return Statuses",
    x = NULL,
    y = NULL
  ) +
  theme_void() +
  theme(legend.title = element_blank())
```

```{r}
top_products <- cleaned_data %>%
  group_by(Description) %>%  
  summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE)) %>%  
  arrange(desc(TotalSales)) %>%  
  slice(1:10)  

ggplot(top_products, aes(x = reorder(Description, TotalSales), y = TotalSales)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +  
  labs(
    title = "Top 10 Products by Total Sales",
    x = "Product Description",
    y = "Total Sales"
  ) +
  theme_minimal()
```
```{r}
cleaned_data <- cleaned_data %>%
  mutate(Year = format(InvoiceDate, "%Y")) 

category_sales_yearly <- cleaned_data %>%
  group_by(Year, Category) %>%
  summarise(
    TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE), 
    .groups = "drop"
  )

category_sales_yearly$Year <- factor(category_sales_yearly$Year, levels = unique(category_sales_yearly$Year))

ggplot(category_sales_yearly, aes(x = Year, y = TotalSales, fill = Category)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(
    title = "Stacked Sales by Category Over Time (Yearly)",
    x = "Year",
    y = "Total Sales",
    fill = "Category"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = comma) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
sales_by_payment <- cleaned_data %>%
  group_by(PaymentMethod) %>%
  summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE))

ggplot(sales_by_payment, aes(x = TotalSales, y = reorder(PaymentMethod, TotalSales))) +
  geom_bar(stat = "identity", fill = "darkgreen") +
  coord_flip() +
  labs(
    title = "Total Sales by Payment Method",
    x = "Payment Method",
    y = "Total Sales"
  ) +
  scale_x_continuous(labels = comma) +
  theme_minimal()
```

```{r}
top_products <- cleaned_data %>%
  group_by(Description) %>%
  summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE)) %>%
  arrange(desc(TotalSales)) %>%
  slice_head(n = 10)

top_products <- top_products %>%
  mutate(Percentage = TotalSales / sum(TotalSales) * 100) 

pie <- ggplot(top_products, aes(x = "", y = TotalSales, fill = Description)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  geom_text(
    aes(label = paste0(round(Percentage, 1), "%")), 
    position = position_stack(vjust = 0.5) 
  ) +
  labs(
    title = "Top 10 Products by Total Sales",
    x = NULL,
    y = NULL
  ) +
  theme_void() + 
  theme(
    legend.title = element_blank(), 
    plot.title = element_text(hjust = 0.5) 
  )

pie
```

```{r}
sales_by_priority <- cleaned_data %>%
  group_by(OrderPriority) %>%
  summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE))

ggplot(sales_by_priority, aes(x = TotalSales, y = reorder(OrderPriority, TotalSales))) +
  geom_bar(stat = "identity", fill = "orange") +
  coord_flip() +
  labs(
    title = "Sales Distribution by Order Priority",
    x = "Order Priority",
    y = "Total Sales"
  ) +
   scale_x_continuous(labels = comma) +
  theme_minimal()
```


```{r}
sales_by_category_return <- cleaned_data %>%
  group_by(Category, ReturnStatus) %>%
  summarise(TotalSales = sum(UnitPrice * Quantity, na.rm = TRUE))

ggplot(sales_by_category_return, aes(x = Category, y = TotalSales, fill = ReturnStatus)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(
    title = "Total Sales by Category and Return Status",
    x = "Category",
    y = "Total Sales",
    fill = "Return Status"
  ) +
  scale_y_continuous(labels = comma) +
  theme_minimal()
```

# Hypothesis Testing

## Hypothsis 1

**Null Hypothesis (H₀)**: There is no significant association between the mode of payment and customer segmentation based on purchase frequency.

**Alternative Hypothesis (H₁)**: There is a significant association between the mode of payment and customer segmentation based on purchase frequency.

**Mode of Test:** Chi-square test for independence

```{r}
unique(cleaned_data$PaymentMethod)
```

```{r}
payment_segregation <- table(cleaned_data$PaymentMethod, cleaned_data$Category)
chisq_test <- chisq.test(payment_segregation)
print(chisq_test)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that there is no significant association between mode of payment and customer segmentation based on purchase frequency. Based on the result we do not have enough evidence to say that there is an association between the 2 parameters.

## Hypothesis 2

**Null Hypothesis (H₀)**: Discounts have no significant impact on the average quantity purchased.

**Alternative Hypothesis (H₁)**: Discounts have a significant impact on the average quantity purchased.

**Mode of Test:** Independent samples t-test

```{r}
t_test <- t.test(Quantity ~ Discount > 0.1, data = cleaned_data)  
print(t_test)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that discount has no significant impact on average quantity purchased. The confidence interval further indicates that there's no strong evidence for a significant difference in the average quantity purchased with and without a discount.

## Hypothesis 3

**Null Hypothesis (H₀)**: The average shipping cost does not vary significantly between shipment providers.

**Alternative Hypothesis (H₁)**: The average shipping cost varies significantly between shipment providers.

**Mode of Test:** One-way ANOVA

```{r}
anova <- aov(ShippingCost ~ ShipmentProvider, data = cleaned_data)
summary(anova)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that there is no significant difference in the average shipping costs between the different shipment providers. And the low F-value is also suggesting that the variation between shipment providers is small compared to the variation within them. In conclusion, the type of shipment provider doesn’t have a strong impact on the cost of shipping.

## Hypothesis 4

**Null Hypothesis (H₀)**: There is no significant difference in sales volume between online and in-store channels.

**Alternative Hypothesis (H₁)**: Sales volume differs significantly between online and in-store channels.

**Mode of Test:** Independent samples t-test

```{r}
t_test2 <- t.test(Quantity ~ SalesChannel, data = cleaned_data)
print(t_test2)
```
The **p-value** is **greater** than **0.05**, which means we **fail to reject null hypothesis** and this suggests that there is a statistically no significant difference in sales volume between online and in-store channels. The confidence interval is further supporting the conclusion that there is no significant difference in sales volume between the two channels.

## Hypothesis 5

**Null Hypothesis (H₀)**: Return rates are not significantly higher for any particular product category.

**Alternative Hypothesis (H₁)**: Return rates are significantly higher for certain product categories.

**Mode of Test:** Chi-square test for independence

```{r}
return_category <- table(cleaned_data$ReturnStatus, cleaned_data$Category)
chisq_test2 <- chisq.test(return_category)
print(chisq_test2)
```
The **p-value** is **greater** than **0.05**, hence we **fail to reject the null hypothesis** and this suggests that there is no significant difference in return rates between the product categories. Based on the result we do not have enough evidence to say that there is an association between the 2 parameters.

## Note

**Failing to reject the null hypothesis doesn't mean the null hypothesis is true—it just means you don’t have enough evidence to reject it.**

# Models

## SMART QUESTION 1

**Can we classify customers into segments (e.g., Low, Medium, High value) based on purchase frequency, product preferences, and payment methods?**

We build **Classification Tree** model to classify customers into predefined segments based on predictors like purchase frequency, product preferences, and payment methods. The focus of our SMART question is on prediction.
 
We start to aggregate features by grouping CustomerID. Then we define the customer_segment variable based on total_spend and categorized customers into "Low," "Medium," and "High" segments. Next we convert and encode preferred_payment and preferred_category to numeric form for model compatibility.

```{r}
customer_data <- cleaned_data %>%
  group_by(CustomerID) %>%
  summarize(
    purchase_frequency = n_distinct(InvoiceNo),
    total_quantity = sum(Quantity, na.rm = TRUE),
    total_spend = sum(UnitPrice * Quantity, na.rm = TRUE),
    avg_discount = mean(Discount, na.rm = TRUE),
    preferred_payment = as.character(names(sort(table(PaymentMethod), decreasing = TRUE)[1])),
    preferred_category = as.character(names(sort(table(Category), decreasing = TRUE)[1]))
  )

spend_summary <- summary(customer_data$total_spend)
low_threshold <- spend_summary["1st Qu."] 
high_threshold <- spend_summary["3rd Qu."] 

customer_data <- customer_data %>%
  mutate(
    customer_segment = case_when(
      total_spend < low_threshold ~ "Low",
      total_spend >= low_threshold & total_spend < high_threshold ~ "Medium",
      total_spend >= high_threshold ~ "High"
    )
  )

customer_data$preferred_payment <-  as.factor(customer_data$preferred_payment)

customer_data$preferred_category <- as.factor(customer_data$preferred_category)


customer_data$preferred_payment <- as.numeric(customer_data$preferred_payment)

customer_data$preferred_category <- as.numeric(customer_data$preferred_category)
```

We split the data into train and test set where we set 70% of data to be randomly selected as train data and the rest as test data. Then we apply the classification tree model.
```{r}
set.seed(123)
train_indices <- sample(1:nrow(customer_data), 0.7 * nrow(customer_data))
train_data <- customer_data[train_indices, ]
test_data <- customer_data[-train_indices, ]


classification_tree <- rpart(
  customer_segment ~ purchase_frequency + total_quantity + avg_discount + preferred_payment + preferred_category,
  data = train_data,
  method = "class"
)
```

```{r}
summary(classification_tree) 
```
```{r}
fancyRpartPlot(classification_tree)
```
The model begins by predicting the **Medium** class at the **root node**, with **6397 observations** in total. The first split occurs based on the variable total_quantity, which is identified as the most significant predictor. Observations where total_quantity < 8.5 are directed to Node 2, while those with total_quantity >= 8.5 are directed to Node 3.

At **Node 2**, there are **1,002 observations**, and the model confidently predicts a majority of customers under Low segment, indicating that those with lower purchase quantities are most likely classified in this segment. On the other hand, **Node 3**, containing **5,377 observations**, continues to predict the Medium segment as the majority class. 

A subsequent split occurs at total_quantity >= 27.5, further refining the classification into Node 6 and Node 7. **Node 6** includes **2,910 observations**, with a higher likelihood of customers being classified as High, indicating that moderate purchase quantities begin to influence the prediction towards high-value segments.

At Node 6, the model makes another split at total_quantity >= 60.5, dividing customers further into Node 12 and Node 13. **Node 12** contains **117 observations** and achieves near-perfect accuracy, with 92.3% of customers being classified as High, reflecting that customers with extremely high purchase quantities are almost in this segment. Meanwhile, **Node 13**, with **2,793 observations**, also predicts High.

Finally, **Node 7**, containing **2,467 observations**, predicts the Medium segment with high confidence. At this node, 72.7% of customers are classified as Medium. Additional splits within **Node 13** further fine-tune the prediction for High and Medium segments based on thresholds like total_quantity >= 38.5.

Overall, the model's accuracy varies by segment. The model performs best for **High** segment customers, with a high accuracy of **95.7%**, indicating that total_quantity is the strongest predictor for high-value customers. For **Medium** segment customers, the accuracy is still strong at **88.8%**, while the model has **80.8%** accuracy when predicting **Low** segment customers.

Evaluation

```{r}

```

## SMART QUESTION 2

**What factors drive product demand, and how can we predict the quantity sold based on discounts, order priority, and customer demographics?** 

We build **Linear regression** model since we are analyzing relationships between predictors (e.g., discounts, order priority) and the target (quantity sold). The focus of our SMART question is inference.

## SMART QUESTION 3

**How do shipment providers, warehouse locations, and order priority influence shipping costs, and how can we predict cost efficiency?**

We build **Linear Regression** model because we want to quantify the relationship between shipping cost based on ShipmentProvider, WarehouseLocation and OrderPriority. The focus of our SMART question is on inference as well as prediction.

We create a df with only relevant columns and then convert the categorical variables to factor.

```{r}
logistics_data <- cleaned_data %>%
  select(ShippingCost, ShipmentProvider, WarehouseLocation, OrderPriority) %>%
  filter(!is.na(ShippingCost))  

logistics_data$ShipmentProvider <- as.factor(logistics_data$ShipmentProvider)
logistics_data$WarehouseLocation <- as.factor(logistics_data$WarehouseLocation)
logistics_data$OrderPriority <- as.factor(logistics_data$OrderPriority)
```

We apply the Linear Regression Model.
```{r}
lm_model <- lm(ShippingCost ~ ShipmentProvider + WarehouseLocation + OrderPriority, data = logistics_data)

summary(lm_model)
```

Evaluation
```{r}


```

## SMART QUESTION 4

**What factors influence whether a sale occurs online or in-store, and how can we classify sales channel based on customer and order characteristics?**

We build **Logistic Regression** model because we want to find a binary outcome. The focus of our SMART question is prediction.

```{r}


```

## SMART QUESTION 5

**How can we predict product returns pattern based on product type, discount status, and customer segment, and what factors influence return rates ?**

We build **Logistic Regression** model because we want to find binary outcome. The focus of our SMART question is inference.

```{r}


```
